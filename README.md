# ğŸš€ Kafka Sensor Data Processing

This project implements a real-time sensor data processing system using Apache Kafka.  
A producer generates sensor data, which is processed and stored in dedicated topics.

## ğŸ“¦ **Project Structure**
```bash
â”œâ”€â”€ kafka_config.py          # Kafka configuration (server, username, password)
â”œâ”€â”€ alerts_conditions.csv     # Alert conditions configuration file
â”œâ”€â”€ kafka_connection_test.py # Script to check connection with the Server
â”œâ”€â”€ delete_topics.py      # Reset Kafka Topics (if needed)
â”œâ”€â”€ 01_kafka_create_topics.py   # Script to create Kafka topics
â”œâ”€â”€ 02_sensor_data_producer.py  # Producer that generates sensor data
â”œâ”€â”€ 03_sensor_alert_processor.py  # Processor that analyzes sensor data and generates alerts
â”œâ”€â”€ 04_alerts_consumer.py       # Consumer that listens for temperature and humidity alerts
â”œâ”€â”€ 05_sliding_window_processor.py  # New processor to implement sliding window and generate alerts


```


ğŸ“Œ Features:

- âœ… Sends simulated sensor data to Kafka
- âœ… Detects critical temperature and humidity values
- âœ… Generates alerts when threshold values are exceeded
- âœ… Listens for alerts via a consumer

ğŸ”¥ New Features in This Version
- âœ… Sliding Window Aggregation â€“ Calculates average temperature and humidity using a 1-minute window with a 30-second slide interval for real-time monitoring.
- âœ… Dynamic Alert Conditions â€“ Alerts are now dynamically loaded from alerts_conditions.csv, allowing easy updates without modifying the code.
- âœ… Multiple Alert Conditions â€“ The system checks sensor data against multiple alert thresholds (e.g., too hot, too cold, too dry, too humid).
- âœ… Automated Filtering & Alerting â€“ Cross-checks aggregated values with conditions and sends alerts only when thresholds are exceeded.
- âœ… Kafka Topic-Based Processing â€“ Uses dedicated Kafka topics:
building_sensors_hellcat_topic â€“ Receives raw sensor data
alerts_hellcat_topic â€“ Stores processed alerts
- âœ… Efficient Data Handling â€“ Implements buffered message processing and auto-cleanup of outdated data from the aggregation window.
- âœ… Auto-Commit for Kafka Consumers â€“ Ensures each message is processed and committed to prevent duplicate processing.
- âœ… Scalability â€“ Multiple sensor producers and processors can run simultaneously without conflicts.

## ğŸ” Checking the Connection with the Server

Run the following command to test the Kafka connection:
``` bash
python3 kafka_connection_test.py
```

![Description of Image](assets/kafka_connection_test.png)

## ğŸš€ How to Run the Project

1ï¸âƒ£ Create Kafka Topics

``` bash
python3 01_kafka_create_topics.py
```
![Description of Image](assets/Create_Kafka_Topics.png)

âŒ Reset Kafka Topics (if needed)

``` bash
python3 delete_topics.py
```
![Description of Image](assets/Reset_Kafka_Topics.png)

2ï¸âƒ£ Start the Producer (Simulating Sensor Data)

``` bash
python3 02_sensor_data_producer.py
```
![Description of Image](assets/Producer.png)

3ï¸âƒ£ Start the Data Processor (Generates Alerts)

``` bash
python3 03_sensor_alert_processor.py
```
![Description of Image](assets/Processor.png)

4ï¸âƒ£ Start the Alerts Consumer

``` bash
python3 04_alerts_consumer.py
```
![Description of Image](assets/Consumer.png)

